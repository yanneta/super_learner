{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNetCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmlb import fetch_data, regression_dataset_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionally interpretable super learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_assignments(train_X, K=6):\n",
    "    data = {'index': range(len(train_X)), 'group':  np.random.choice(K, len(train_X)) }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "alphas=[1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 4, 8, 16, 32, 64, 132]\n",
    "class BaseModel:\n",
    "    def __init__(self, model_type):\n",
    "        self.model_type = model_type\n",
    "        self.model = self.create_model()\n",
    "        if model_type not in range(1,7):\n",
    "            print(\"model_type should be in the interval [1, 6]\")\n",
    "\n",
    "    def create_model(self):\n",
    "        method_name = 'model_' + str(self.model_type)\n",
    "        method = getattr(self, method_name, lambda: \"nothing\")\n",
    "        return method()\n",
    "\n",
    "    def model_1(self):\n",
    "        return RidgeCV(cv=5, alphas=alphas)\n",
    "\n",
    "    def model_2(self):\n",
    "        return ElasticNetCV(cv=5, random_state=0, l1_ratio=0.5)\n",
    "\n",
    "    def model_3(self):\n",
    "        return ElasticNetCV(cv=5, random_state=0, l1_ratio=1)\n",
    "\n",
    "    def model_4(self):\n",
    "        return DecisionTreeRegressor(max_depth=4, max_features=0.9)\n",
    "\n",
    "    def model_5(self):\n",
    "        return DecisionTreeRegressor(max_depth=5, max_features=0.9)\n",
    "\n",
    "    def model_6(self):\n",
    "        return DecisionTreeRegressor(max_depth=6, max_features=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(train_X, train_y, m_type):\n",
    "    N = train_X.shape[0]\n",
    "    n = int(2.5*N/np.log(N))\n",
    "    ind = np.random.choice(N, n, replace=False)\n",
    "    X = train_X[ind]\n",
    "    y = train_y[ind]\n",
    "    base_model = BaseModel(m_type)\n",
    "    base_model.model.fit(X, y)\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_initial_K_models(train_X, train_y, model_types):\n",
    "    models = []\n",
    "    N = train_X.shape[0]\n",
    "    n = int(3*N/np.log(N))\n",
    "    for k in range(len(model_types)):\n",
    "        ind = np.random.choice(N, n, replace=False)\n",
    "        X = train_X[ind]\n",
    "        y = train_y[ind]\n",
    "        if len(ind) > 10:\n",
    "            base_model = BaseModel(model_types[k])\n",
    "            base_model.model.fit(X, y)\n",
    "            models.append(base_model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=[1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 4, 8, 16, 32, 64, 132]\n",
    "\n",
    "def fit_K_models(train_X, train_y, oracle, models, K, p=0.8):\n",
    "    # sample to address overfitting \n",
    "    N = train_X.shape[0]\n",
    "    ind = np.random.choice(N, int(p*N), replace=False)\n",
    "    X = train_X[ind]\n",
    "    y = train_y[ind]\n",
    "    # assigning points using oracle\n",
    "    # this will be modified \n",
    "    groups = assign_points(X, oracle)\n",
    "                \n",
    "    if len(groups.group.unique()) < K:\n",
    "        groups, models = relabel_groups(groups, models)\n",
    "        K = len(groups.group.unique())\n",
    "        \n",
    "    model_types = [m.model_type for m in models]\n",
    "    models = []\n",
    "    for k in range(len(model_types)):\n",
    "        ind = groups[groups[\"group\"] == k].index.values\n",
    "        X_k = X[ind]\n",
    "        y_k = y[ind]\n",
    "        if len(ind) > 10:\n",
    "            base_model = BaseModel(model_types[k])\n",
    "            base_model.model.fit(X_k, y_k)\n",
    "            models.append(base_model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_K_model_loss(train_X, train_y, models):\n",
    "    L = []\n",
    "    for i in range(len(models)):\n",
    "        loss = (models[i].model.predict(train_X) - train_y)**2\n",
    "        L.append(loss)\n",
    "    L = np.array(L)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(L, K):\n",
    "    JI_K = inv(np.ones((K, K)) - np.identity(K))\n",
    "    W = []\n",
    "    for i in range(L.shape[1]):\n",
    "        w_i = np.matmul(JI_K, L[:,i])\n",
    "        W.append(w_i)\n",
    "    return np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_dataset(train_X, train_y, models, p=0.7):\n",
    "    # sample to address overfitting\n",
    "    K = len(models)\n",
    "    N = train_X.shape[0]\n",
    "    n = int(p*N)\n",
    "    idx = np.random.choice(N, n, replace=False)\n",
    "    X = train_X[idx]\n",
    "    Y = train_y[idx]\n",
    "    L = compute_K_model_loss(X, Y, models)\n",
    "    W = compute_weights(L, K)\n",
    "    X_ext = []\n",
    "    y_ext = []\n",
    "    w_ext = []\n",
    "    for i in range(K):\n",
    "        X_ext.append(X.copy())\n",
    "        y_ext.append(i*np.ones(n))\n",
    "        w_ext.append(W[:, i])\n",
    "    X_ext = np.concatenate(X_ext, axis=0)\n",
    "    y_ext = np.concatenate(y_ext, axis=0)\n",
    "    w_ext = np.concatenate(w_ext, axis=0)\n",
    "    return X_ext, y_ext, w_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_oracle_model(D_in, K, N):\n",
    "    \"\"\" Returns an oracle model\n",
    "    \n",
    "    The size of the hidden layer is a function of the\n",
    "    amount of training data\n",
    "    \"\"\"\n",
    "    H = np.minimum(int(2*np.log(N)**2), 150)\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(D_in, H),\n",
    "        nn.BatchNorm1d(H),\n",
    "        nn.ReLU(),\n",
    "        torch.nn.Linear(H, K))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss(beta, f_hat, y, w):\n",
    "    y_hat = np.exp(beta*f_hat)\n",
    "    den = (np.exp(beta*f_hat)).sum(axis=1)\n",
    "    y_hat = np.array([y_hat[i]/den[i] for i in range(len(den))])\n",
    "    loss = w*((y * (1- y_hat)).sum(axis=1))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounded_loss(beta, y_hat, y , w):\n",
    "    #y_hat = beta*y_hat\n",
    "    y_hat = F.softmax(y_hat, dim=1)\n",
    "    loss = (y*(1-y_hat)).sum(dim=1)\n",
    "    return (w*loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, K, learning_rate = 0.01, epochs=100):\n",
    "    beta = 1\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    KK = epochs//10 + 1\n",
    "    model.train()\n",
    "    for t in range(epochs):\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        for x, y, w in train_dl:\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda().long()\n",
    "            w = w.cuda().float()\n",
    "            y_onehot = torch.FloatTensor(y.shape[0], K).cuda()\n",
    "            y_onehot.zero_()\n",
    "            y_onehot = y_onehot.scatter_(1, y.unsqueeze(1), 1)\n",
    "            y_hat = model(x)\n",
    "            loss = bounded_loss(beta, y_hat, y_onehot , w)\n",
    "       \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()*y.size(0)\n",
    "            total += y.size(0)\n",
    "        if t % KK == 0: print(\"epoch %d loss %.4f\" % (t, total_loss/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_points(X, oracle):\n",
    "    x = torch.tensor(X).float()\n",
    "    y_hat = oracle(x.cuda())\n",
    "    _, pred = torch.max(y_hat, 1)\n",
    "    data = {'index': range(len(X)), 'group': pred.cpu().numpy()  }\n",
    "    return pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_groups(groups, models):\n",
    "    unique_models = groups.group.unique()\n",
    "    old2new = {x:i for i,x in enumerate(unique_models)}\n",
    "    model_subset = [models[i] for i in unique_models]\n",
    "    groups.group = np.array([old2new[x] for x in groups.group.values])\n",
    "    return groups, model_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, y, oracle, models):\n",
    "    oracle.eval()\n",
    "    x = torch.tensor(X).float()\n",
    "    y = torch.tensor(y).float()\n",
    "    y_hat = oracle(x.cuda())\n",
    "    _, ass = torch.max(y_hat, 1)\n",
    "    preds = []\n",
    "    ys = []\n",
    "    k = 0\n",
    "    #print(ass)\n",
    "    for i in range(len(models)):\n",
    "        xx = x[ass==i]\n",
    "        yy = y[ass==i]\n",
    "        if len(xx) > 0:\n",
    "            k =+1\n",
    "            pred = models[i].model.predict(xx.cpu().numpy())\n",
    "            preds.append(pred)\n",
    "            ys.append(yy.cpu().numpy())\n",
    "\n",
    "    if k==1:\n",
    "        preds, ys = preds[0], ys[0]\n",
    "    else:\n",
    "        preds = np.hstack(preds)\n",
    "        ys = np.hstack(ys)\n",
    "    r2 = r2_score(ys, preds)\n",
    "    res = (ys - preds)**2\n",
    "    return res.mean(), r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_loss(X, y, model):\n",
    "    pred = model.model.predict(X)\n",
    "    r2 = r2_score(y, pred)\n",
    "    res = (y - pred)**2\n",
    "    return res.mean(), r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OracleDataset(Dataset):\n",
    "    def __init__(self, X, y, w):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.w[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_models(train_X, train_y, valid_X, valid_y):\n",
    "    best_model = None\n",
    "    best_valid_r2 = 0\n",
    "    best_model_type = 0\n",
    "    for k in range(1,7):\n",
    "        base_model = BaseModel(k)\n",
    "        base_model.model.fit(train_X, train_y)\n",
    "        valid_r2 = base_model.model.score(valid_X, valid_y)\n",
    "        if valid_r2 > best_valid_r2:\n",
    "            best_valid_r2 = valid_r2\n",
    "            best_model_type = k\n",
    "            best_model = base_model.model\n",
    "    return best_valid_r2, best_model, [best_model_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/data2/yinterian/tmp/\")\n",
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))\n",
    "\n",
    "def LR_range_finder(model, train_dl, K, lr_low=1e-5, lr_high=1, epochs=10):\n",
    "    losses = []\n",
    "    p = PATH/\"mode_tmp.pth\"\n",
    "    save_model(model, str(p))\n",
    "    iterations = epochs * len(train_dl)\n",
    "    delta = (lr_high - lr_low)/iterations\n",
    "    lrs = [lr_low + i*delta for i in range(iterations)]\n",
    "    model.train()\n",
    "    ind = 0\n",
    "    for i in range(epochs):\n",
    "        for x, y, w in train_dl:\n",
    "            optimizer = get_optimizer(model, lr=lrs[ind])\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda().long()\n",
    "            w = w.cuda().float()\n",
    "            y_onehot = torch.FloatTensor(y.shape[0], K).cuda()\n",
    "            y_onehot.zero_()\n",
    "            y_onehot = y_onehot.scatter_(1, y.unsqueeze(1), 1)\n",
    "            y_hat = model(x)\n",
    "            loss = bounded_loss(beta, y_hat, y_onehot , w)\n",
    "       \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ind +=1\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    load_model(model, str(p))\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle_LR_range_finder(train_X, train_y, K=6):\n",
    "    groups = random_assignments(train_X, K)\n",
    "    models = fit_K_models(train_X, train_y, groups, model_types)\n",
    "    K = len(models)\n",
    "    print(\"models\")\n",
    "    X_ext, y_ext, w_ext = create_extended_dataset(train_X, train_y, models)\n",
    "    train_ds = OracleDataset(X_ext, y_ext, w_ext)\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    model = create_oracle_model(train_X.shape[1], K, N).cuda()\n",
    "    lrs, losses = LR_range_finder(model, train_dl, K, lr_low=1e-5, lr_high=0.5)\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"1028_SWD\"\n",
    "X, y = fetch_data(dataset, return_X_y=True, local_cache_dir='/data2/yinterian/pmlb/')\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_map = {\"1028_SWD\": 0.15, \"1029_LEV\" :0.15, \"1030_ERA\": 0.15, \"1191_BNG_pbc\": 0.02,\n",
    "         \"1193_BNG_lowbwt\": 0.1, \"1196_BNG_pharynx\": 0.015, \"1199_BNG_echoMonths\": 0.3,\n",
    "         \"1203_BNG_pwLinear\": 0.05, \"1595_poker\": 0.01, \"1201_BNG_breastTumor\": 0.05, \"197_cpu_act\": 0.2,\n",
    "         \"201_pol\": 0.15, \"215_2dplanes\": 0.1, \"218_house_8L\": 0.05, \"225_puma8NH\": 0.15,\n",
    "         \"227_cpu_small\":0.15, \"294_satellite_image\": 0.15, \"344_mv\": 0.1,\n",
    "          \"4544_GeographicalOriginalofMusic\": 0.15, \"503_wind\": 0.1, \"529_pollen\": 0.1,\n",
    "         \"537_houses\": 0.15, \"562_cpu_small\": 0.15, \"564_fried\": 0.1, \"573_cpu_act\": 0.15,\n",
    "         \"574_house_16H\": 0.15, \"583_fri_c1_1000_50\": 0.15, \"586_fri_c3_1000_25\": 0.15 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1199_BNG_echoMonths (13996, 9)\n"
     ]
    }
   ],
   "source": [
    "# difficult problems 5, 7, 22\n",
    "dataset = \"1201_BNG_breastTumor\"\n",
    "dataset = \"1199_BNG_echoMonths\"\n",
    "\n",
    "state=2\n",
    "X, y = fetch_data(dataset, return_X_y=True, local_cache_dir='/data2/yinterian/pmlb/')\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=state, test_size = 0.2)\n",
    "valid_X, test_X, valid_y, test_y = train_test_split(test_X, test_y, random_state=state,\n",
    "                                                            test_size =0.5) \n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "valid_X = scaler.fit_transform(valid_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "print(dataset, train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_r2, best_model, best_model_types = baseline_models(train_X, train_y,\n",
    "                                                              valid_X, valid_y)\n",
    "best_test_r2 = best_model.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4601600617324513,\n",
       " DecisionTreeRegressor(criterion='mse', max_depth=6, max_features=None,\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'),\n",
       " [6],\n",
       " 0.4460224317848724)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_valid_r2, best_model, best_model_types, best_test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_loop(state, selected_datasets):\n",
    "    for dataset in selected_datasets:\n",
    "        learning_rate = lr_map.get(dataset, 0.15)\n",
    "        X, y = fetch_data(dataset, return_X_y=True, local_cache_dir='/data2/yinterian/pmlb/')\n",
    "        train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=state, test_size = 0.2)\n",
    "        valid_X, test_X, valid_y, test_y = train_test_split(test_X, test_y, random_state=state, test_size =0.5)\n",
    "        scaler = StandardScaler()\n",
    "        train_X = scaler.fit_transform(train_X)\n",
    "        test_X = scaler.transform(test_X)\n",
    "        valid_X = scaler.transform(valid_X)\n",
    "\n",
    "        best_valid_r2, best_model, best_model_types = baseline_models(train_X, train_y, valid_X, valid_y)\n",
    "        best_test_r2 = best_model.score(test_X, test_y)\n",
    "        print(\"best valid R^2 %.3f best model type %d\" % (best_valid_r2, best_model_types[0]))\n",
    "        best_oracle = None\n",
    "        best_models = [best_model] \n",
    "\n",
    "        #K = 6\n",
    "        #groups = random_assignments(train_X, K)\n",
    "\n",
    "        batch_size = 100000\n",
    "        # number of iterations depends on the number of training points\n",
    "        N = train_X.shape[0]\n",
    "        N_iter = int(3000/np.log(N)**2)\n",
    "        print(\"Number of training points %d, number iterations %d\" % (N, N_iter))\n",
    "\n",
    "        model_types = [x for x in range(1,7)]\n",
    "        K = len(model_types)\n",
    "        INIT_FLAG = True\n",
    "        oracle = None\n",
    "        for i in range(16):\n",
    "            if i == 8: INIT_FLAG = True\n",
    "            \n",
    "            if not INIT_FLAG:\n",
    "                models = fit_K_models(train_X, train_y, oracle, models, K, p=0.9)\n",
    "                if len(models) == 1:\n",
    "                    INIT_FLAG = True  \n",
    "            \n",
    "            if INIT_FLAG:\n",
    "                model_types = [x for x in range(1,7)] + [1,3,6,6,6,6,6,6]\n",
    "                models = fit_initial_K_models(train_X, train_y, model_types)\n",
    "                INIT_FLAG = False\n",
    "            \n",
    "            K = len(models)\n",
    "            print(\"Iteration %d K is %d\" % (i+1, K))\n",
    "            if K == 1:\n",
    "                INIT_FLAG = True\n",
    "\n",
    "            if not INIT_FLAG:\n",
    "                X_ext, y_ext, w_ext = create_extended_dataset(train_X, train_y, models, p=0.9)\n",
    "                train_ds = OracleDataset(X_ext, y_ext, w_ext)\n",
    "                train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "                oracle = create_oracle_model(train_X.shape[1], K, N).cuda()\n",
    "                train_model(oracle, train_dl, K, learning_rate, N_iter)\n",
    "            \n",
    "            \n",
    "            if not INIT_FLAG:\n",
    "                train_loss, train_r2 = compute_loss(train_X, train_y, oracle, models)\n",
    "                valid_loss, valid_r2 = compute_loss(valid_X, valid_y, oracle, models)\n",
    "                test_loss, test_r2 = compute_loss(test_X, test_y, oracle, models)\n",
    "\n",
    "\n",
    "            print(\"train loss %.3f valid loss %.3f\", train_loss, valid_loss)\n",
    "            print(\"train R^2 %.3f valid R^2 %.3f\", train_r2, valid_r2)\n",
    "            if valid_r2 >= best_valid_r2:\n",
    "                best_train_r2 = train_r2\n",
    "                best_valid_r2 = valid_r2\n",
    "                best_K = K\n",
    "                best_models = models\n",
    "                best_model_types = [m.model_type for m in models]\n",
    "                best_test_r2 = test_r2 \n",
    "        \n",
    "        results = \"dataset %s state %d K %d test ISL %.3f valid ISL %.3f model_types %s\" % (\n",
    "                dataset, state, len(best_models), best_test_r2, best_valid_r2, str(best_model_types))\n",
    "        print(results)\n",
    "        #f.write(results)\n",
    "        #f.write('\\n')\n",
    "        #f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best valid R^2 0.611 best model type 6\n",
      "Number of training points 6553, number iterations 38\n",
      "Iteration 1 K is 14\n",
      "epoch 0 loss 1.0070\n",
      "epoch 4 loss 0.7157\n",
      "epoch 8 loss 0.6951\n",
      "epoch 12 loss 0.6865\n",
      "epoch 16 loss 0.6799\n",
      "epoch 20 loss 0.6733\n",
      "epoch 24 loss 0.6680\n",
      "epoch 28 loss 0.6641\n",
      "epoch 32 loss 0.6621\n",
      "epoch 36 loss 0.6606\n",
      "train loss %.3f valid loss %.3f 7.2258932426656495 8.139765589217903\n",
      "train R^2 %.3f valid R^2 %.3f 0.6801285749411117 0.5430950989156202\n",
      "Iteration 2 K is 4\n",
      "epoch 0 loss 4.3251\n",
      "epoch 4 loss 2.6868\n",
      "epoch 8 loss 2.6024\n",
      "epoch 12 loss 2.5548\n",
      "epoch 16 loss 2.5392\n",
      "epoch 20 loss 2.5200\n",
      "epoch 24 loss 2.5083\n",
      "epoch 28 loss 2.5018\n",
      "epoch 32 loss 2.4942\n",
      "epoch 36 loss 2.4897\n",
      "train loss %.3f valid loss %.3f 9.992798919920448 13.139159047455314\n",
      "train R^2 %.3f valid R^2 %.3f 0.6668817560375722 0.5661441312086251\n",
      "Iteration 3 K is 2\n",
      "epoch 0 loss 6.8983\n",
      "epoch 4 loss 5.4638\n",
      "epoch 8 loss 5.4637\n",
      "epoch 12 loss 5.4637\n",
      "epoch 16 loss 5.4637\n",
      "epoch 20 loss 5.4637\n",
      "epoch 24 loss 5.4637\n",
      "epoch 28 loss 5.4637\n",
      "epoch 32 loss 5.4637\n",
      "epoch 36 loss 5.4637\n",
      "train loss %.3f valid loss %.3f 10.737408808893441 13.72394079328767\n",
      "train R^2 %.3f valid R^2 %.3f 0.6593903393602141 0.569755745985689\n",
      "Iteration 4 K is 14\n",
      "epoch 0 loss 1.0065\n",
      "epoch 4 loss 0.7263\n",
      "epoch 8 loss 0.6979\n",
      "epoch 12 loss 0.6847\n",
      "epoch 16 loss 0.6759\n",
      "epoch 20 loss 0.6660\n",
      "epoch 24 loss 0.6593\n",
      "epoch 28 loss 0.6542\n",
      "epoch 32 loss 0.6483\n",
      "epoch 36 loss 0.6485\n",
      "train loss %.3f valid loss %.3f 9.187027767265628 11.379592186357124\n",
      "train R^2 %.3f valid R^2 %.3f 0.6353125754668777 0.5446976532437267\n",
      "Iteration 5 K is 6\n",
      "epoch 0 loss 3.3456\n",
      "epoch 4 loss 1.7579\n",
      "epoch 8 loss 1.6333\n",
      "epoch 12 loss 1.5828\n",
      "epoch 16 loss 1.5505\n",
      "epoch 20 loss 1.5215\n",
      "epoch 24 loss 1.4967\n",
      "epoch 28 loss 1.4839\n",
      "epoch 32 loss 1.4713\n",
      "epoch 36 loss 1.4604\n",
      "train loss %.3f valid loss %.3f 5.865733231940886 13.563734889399923\n",
      "train R^2 %.3f valid R^2 %.3f 0.6612717919439351 0.17967445756926825\n",
      "Iteration 6 K is 5\n",
      "epoch 0 loss 3.1264\n",
      "epoch 4 loss 1.9652\n",
      "epoch 8 loss 1.8436\n",
      "epoch 12 loss 1.8151\n",
      "epoch 16 loss 1.7846\n",
      "epoch 20 loss 1.7549\n",
      "epoch 24 loss 1.7404\n",
      "epoch 28 loss 1.7251\n",
      "epoch 32 loss 1.7140\n",
      "epoch 36 loss 1.7020\n",
      "train loss %.3f valid loss %.3f 8.191979556468924 13.469565559149418\n",
      "train R^2 %.3f valid R^2 %.3f 0.7357446758817012 0.5618896408883938\n",
      "Iteration 7 K is 4\n",
      "epoch 0 loss 3.3617\n",
      "epoch 4 loss 2.4170\n",
      "epoch 8 loss 2.2904\n",
      "epoch 12 loss 2.2469\n",
      "epoch 16 loss 2.2026\n",
      "epoch 20 loss 2.1793\n",
      "epoch 24 loss 2.1622\n",
      "epoch 28 loss 2.1477\n",
      "epoch 32 loss 2.1399\n",
      "epoch 36 loss 2.1271\n",
      "train loss %.3f valid loss %.3f 9.360616698686687 13.507811047562553\n",
      "train R^2 %.3f valid R^2 %.3f 0.6930106833925311 0.5355578181211116\n",
      "Iteration 8 K is 4\n",
      "epoch 0 loss 3.4957\n",
      "epoch 4 loss 2.8561\n",
      "epoch 8 loss 2.6150\n",
      "epoch 12 loss 2.5524\n",
      "epoch 16 loss 2.4943\n",
      "epoch 20 loss 2.4536\n",
      "epoch 24 loss 2.4205\n",
      "epoch 28 loss 2.4052\n",
      "epoch 32 loss 2.3856\n",
      "epoch 36 loss 2.4152\n",
      "train loss %.3f valid loss %.3f 10.300208633670588 13.04629673555218\n",
      "train R^2 %.3f valid R^2 %.3f 0.6460729523750236 0.558752761884231\n",
      "Iteration 9 K is 14\n",
      "epoch 0 loss 1.0028\n",
      "epoch 4 loss 0.7084\n",
      "epoch 8 loss 0.6910\n",
      "epoch 12 loss 0.6803\n",
      "epoch 16 loss 0.6728\n",
      "epoch 20 loss 0.6622\n",
      "epoch 24 loss 0.6624\n",
      "epoch 28 loss 0.6614\n",
      "epoch 32 loss 0.6580\n",
      "epoch 36 loss 0.6518\n",
      "train loss %.3f valid loss %.3f 10.142836645622278 16.51734502375681\n",
      "train R^2 %.3f valid R^2 %.3f 0.6938740967181662 0.5320964769398211\n",
      "Iteration 10 K is 4\n",
      "epoch 0 loss 5.0365\n",
      "epoch 4 loss 2.6506\n",
      "epoch 8 loss 2.5779\n",
      "epoch 12 loss 2.4919\n",
      "epoch 16 loss 2.4380\n",
      "epoch 20 loss 2.3972\n",
      "epoch 24 loss 2.3688\n",
      "epoch 28 loss 2.3495\n",
      "epoch 32 loss 2.3371\n",
      "epoch 36 loss 2.3208\n",
      "train loss %.3f valid loss %.3f 9.833016334217772 12.907862538821929\n",
      "train R^2 %.3f valid R^2 %.3f 0.7037065327708141 0.6150474517761563\n",
      "Iteration 11 K is 3\n",
      "epoch 0 loss 4.3725\n",
      "epoch 4 loss 3.4740\n",
      "epoch 8 loss 3.4389\n",
      "epoch 12 loss 3.4119\n",
      "epoch 16 loss 3.3890\n",
      "epoch 20 loss 3.3792\n",
      "epoch 24 loss 3.3742\n",
      "epoch 28 loss 3.3640\n",
      "epoch 32 loss 3.3605\n",
      "epoch 36 loss 3.3531\n",
      "train loss %.3f valid loss %.3f 10.63110385381359 14.664342740135162\n",
      "train R^2 %.3f valid R^2 %.3f 0.6857435591258632 0.5722492776738679\n",
      "Iteration 12 K is 2\n",
      "epoch 0 loss 5.7005\n",
      "epoch 4 loss 4.8160\n",
      "epoch 8 loss 4.7309\n",
      "epoch 12 loss 4.7023\n",
      "epoch 16 loss 4.6931\n",
      "epoch 20 loss 4.6635\n",
      "epoch 24 loss 4.6440\n",
      "epoch 28 loss 4.6290\n",
      "epoch 32 loss 4.6169\n",
      "epoch 36 loss 4.6040\n",
      "train loss %.3f valid loss %.3f 8.233142889998799 11.680801479264137\n",
      "train R^2 %.3f valid R^2 %.3f 0.6924558651020185 0.5541966136164218\n",
      "Iteration 13 K is 2\n",
      "epoch 0 loss 5.8918\n",
      "epoch 4 loss 4.9025\n",
      "epoch 8 loss 4.8316\n",
      "epoch 12 loss 4.7766\n",
      "epoch 16 loss 4.7486\n",
      "epoch 20 loss 4.7359\n",
      "epoch 24 loss 4.7201\n",
      "epoch 28 loss 4.7228\n",
      "epoch 32 loss 4.7112\n",
      "epoch 36 loss 4.7034\n",
      "train loss %.3f valid loss %.3f 7.8750618909713666 13.050091014732097\n",
      "train R^2 %.3f valid R^2 %.3f 0.6912278550960989 0.5045533151069215\n",
      "Iteration 14 K is 2\n",
      "epoch 0 loss 6.0900\n",
      "epoch 4 loss 4.8605\n",
      "epoch 8 loss 4.8112\n",
      "epoch 12 loss 4.7697\n",
      "epoch 16 loss 4.7457\n",
      "epoch 20 loss 4.7323\n",
      "epoch 24 loss 4.7264\n",
      "epoch 28 loss 4.7121\n",
      "epoch 32 loss 4.6932\n",
      "epoch 36 loss 4.6825\n",
      "train loss %.3f valid loss %.3f 7.943469506413445 11.76737516785342\n",
      "train R^2 %.3f valid R^2 %.3f 0.6946558426943666 0.5532137937386559\n",
      "Iteration 15 K is 2\n",
      "epoch 0 loss 5.9638\n",
      "epoch 4 loss 4.6355\n",
      "epoch 8 loss 4.6112\n",
      "epoch 12 loss 4.5797\n",
      "epoch 16 loss 4.5646\n",
      "epoch 20 loss 4.5310\n",
      "epoch 24 loss 4.5137\n",
      "epoch 28 loss 4.4981\n",
      "epoch 32 loss 4.4812\n",
      "epoch 36 loss 4.4671\n",
      "train loss %.3f valid loss %.3f 7.574435667735205 9.845322334222793\n",
      "train R^2 %.3f valid R^2 %.3f 0.6966055821287682 0.6115090378435645\n",
      "Iteration 16 K is 2\n",
      "epoch 0 loss 6.2258\n",
      "epoch 4 loss 4.7927\n",
      "epoch 8 loss 4.6886\n",
      "epoch 12 loss 4.6411\n",
      "epoch 16 loss 4.6351\n",
      "epoch 20 loss 4.6134\n",
      "epoch 24 loss 4.6008\n",
      "epoch 28 loss 4.5966\n",
      "epoch 32 loss 4.5852\n",
      "epoch 36 loss 4.5755\n",
      "train loss %.3f valid loss %.3f 7.567405352246531 10.783587196043383\n",
      "train R^2 %.3f valid R^2 %.3f 0.6939751061958609 0.5485028229494351\n",
      "dataset 225_puma8NH state 2 K 4 test ISL 0.562 valid ISL 0.615 model_types [6, 6, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "main_loop(2, [\"225_puma8NH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        layers = list(resnet.children())[:8]\n",
    "        self.top_model = nn.Sequential(*layers).cuda()\n",
    "        self.bn = nn.BatchNorm1d(512)\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.top_model(x))\n",
    "        x = nn.AdaptiveAvgPool2d((1,1))(x)\n",
    "        x = x.view(x.shape[0], -1) # flattening \n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
