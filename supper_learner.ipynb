{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1027_ESL', '1028_SWD', '1029_LEV', '1030_ERA', '1089_USCrime', '1096_FacultySalaries', '1191_BNG_pbc', '1193_BNG_lowbwt', '1196_BNG_pharynx', '1199_BNG_echoMonths', '1201_BNG_breastTumor', '1203_BNG_pwLinear', '1595_poker', '192_vineyard', '195_auto_price', '197_cpu_act', '201_pol', '207_autoPrice', '210_cloud', '215_2dplanes', '218_house_8L', '225_puma8NH', '227_cpu_small', '228_elusage', '229_pwLinear', '230_machine_cpu', '294_satellite_image', '344_mv', '4544_GeographicalOriginalofMusic', '485_analcatdata_vehicle', '503_wind', '505_tecator', '519_vinnie', '522_pm10', '523_analcatdata_neavote', '527_analcatdata_election2000', '529_pollen', '537_houses', '542_pollution', '547_no2', '556_analcatdata_apnea2', '557_analcatdata_apnea1', '560_bodyfat', '561_cpu', '562_cpu_small', '564_fried', '573_cpu_act', '574_house_16H', '579_fri_c0_250_5', '581_fri_c3_500_25', '582_fri_c1_500_25', '583_fri_c1_1000_50', '584_fri_c4_500_25', '586_fri_c3_1000_25', '588_fri_c4_1000_100', '589_fri_c2_1000_25', '590_fri_c0_1000_50', '591_fri_c1_100_10', '592_fri_c4_1000_25', '593_fri_c1_1000_10', '594_fri_c2_100_5', '595_fri_c0_1000_10', '596_fri_c2_250_5', '597_fri_c2_500_5', '598_fri_c0_1000_25', '599_fri_c2_1000_5', '601_fri_c1_250_5', '602_fri_c3_250_10', '603_fri_c0_250_50', '604_fri_c4_500_10', '605_fri_c2_250_25', '606_fri_c2_1000_10', '607_fri_c4_1000_50', '608_fri_c3_1000_10', '609_fri_c0_1000_5', '611_fri_c3_100_5', '612_fri_c1_1000_5', '613_fri_c3_250_5', '615_fri_c4_250_10', '616_fri_c4_500_50', '617_fri_c3_500_5', '618_fri_c3_1000_50', '620_fri_c1_1000_25', '621_fri_c0_100_10', '622_fri_c2_1000_50', '623_fri_c4_1000_10', '624_fri_c0_100_5', '626_fri_c2_500_50', '627_fri_c2_500_10', '628_fri_c3_1000_5', '631_fri_c1_500_5', '633_fri_c0_500_25', '634_fri_c2_100_10', '635_fri_c0_250_10', '637_fri_c1_500_50', '641_fri_c1_500_10', '643_fri_c2_500_25', '644_fri_c4_250_25', '645_fri_c3_500_50', '646_fri_c3_500_10', '647_fri_c1_250_10', '648_fri_c1_250_50', '649_fri_c0_500_5', '650_fri_c0_500_50', '651_fri_c0_100_25', '653_fri_c0_250_25', '654_fri_c0_500_10', '656_fri_c1_100_5', '657_fri_c2_250_10', '658_fri_c3_250_25', '659_sleuth_ex1714', '663_rabe_266', '665_sleuth_case2002', '666_rmftsa_ladata', '678_visualizing_environmental', '687_sleuth_ex1605', '690_visualizing_galaxy', '695_chatfield_4', '706_sleuth_case1202', '712_chscase_geyser1']\n"
     ]
    }
   ],
   "source": [
    "from pmlb import fetch_data, regression_dataset_names\n",
    "\n",
    "print(regression_dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dataset = []\n",
    "\n",
    "for dataset in regression_dataset_names:\n",
    "    X, y = fetch_data(dataset, return_X_y=True, local_cache_dir='/data2/yinterian/pmlb/')\n",
    "    if X.shape[0] >= 1000:\n",
    "        list_dataset.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_data(list_dataset[3], return_X_y=True, local_cache_dir='/data2/yinterian/pmlb/')\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 5)]\n",
    "max_depth = [int(x) for x in np.linspace(3, 30, num = 5)]\n",
    "max_depth.append(None)\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 57, 105, 152, 200], 'max_depth': [3, 9, 16, 23, 30, None]}\n"
     ]
    }
   ],
   "source": [
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-11-fd670b308a54>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-fd670b308a54>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    random_state=42, n_jobs = 2)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#rf = RandomForestRegressor()\n",
    "#rf_cv = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2,\n",
    "                           random_state=42, n_jobs = 2)\n",
    "#rf_cv.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_scores(train_X, test_X, train_y, test_y):\n",
    "    rf_reg = RandomForestRegressor(n_estimators=10, max_depth=15, n_jobs=10)\n",
    "    ridge_reg = RidgeCV(alphas=alphas)\n",
    "    lasso_reg = LassoCV(cv=5, random_state=0)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    test_X = scaler.transform(test_X)\n",
    "    \n",
    "    rf_reg.fit(train_X, train_y)\n",
    "    lasso_reg.fit(train_X, train_y)\n",
    "    ridge_reg.fit(train_X, train_y)\n",
    "\n",
    "    return rf_reg.score(test_X, test_y), ridge_reg.score(test_X, test_y), lasso_reg.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionally interpretable super learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  group\n",
       "0      0      4\n",
       "1      1      0\n",
       "2      2      4\n",
       "3      3      2\n",
       "4      4      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_assignments(train_X, K=6):\n",
    "    data = {'index': range(len(train_X)), 'group':  np.random.choice(K, len(train_X)) }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "groups = random_assignments(train_X, K=6)\n",
    "groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_K_models(train_X, train_y, groups, alpha, K=6):\n",
    "    models = []\n",
    "    for k in range(K):\n",
    "        ind = groups[groups[\"group\"] == k].index.values\n",
    "        X = train_X[ind]\n",
    "        y = train_y[ind]\n",
    "        ridge_reg = Ridge(alpha=alpha)\n",
    "        ridge_reg.fit(X, y)\n",
    "        models.append(ridge_reg)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_K_model_loss(train_X, train_y, models):\n",
    "    L = []\n",
    "    for i in range(len(models)):\n",
    "        loss = (models[i].predict(train_X) - train_y)**2\n",
    "        L.append(loss)\n",
    "    L = np.array(L)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(L, K):\n",
    "    JI_K = inv(np.ones((K, K)) - np.identity(K))\n",
    "    W = []\n",
    "    for i in range(L.shape[1]):\n",
    "        w_i = np.matmul(JI_K, L[:,i])\n",
    "        W.append(w_i)\n",
    "    return np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_dataset(train_X, train_y, models):\n",
    "    K = len(models)\n",
    "    print(K)\n",
    "    N = train_X.shape[0]\n",
    "    L = compute_K_model_loss(train_X, train_y, models)\n",
    "    W = compute_weights(L, K)\n",
    "    print(W.shape)\n",
    "    X_ext = []\n",
    "    y_ext = []\n",
    "    w_ext = []\n",
    "    for i in range(K):\n",
    "        X_ext.append(train_X.copy())\n",
    "        y_ext.append(i*np.ones(N))\n",
    "        w_ext.append(W[:, i])\n",
    "    X_ext = np.concatenate(X_ext, axis=0)\n",
    "    y_ext = np.concatenate(y_ext, axis=0)\n",
    "    w_ext = np.concatenate(w_ext, axis=0)\n",
    "    return X_ext, y_ext, w_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(D_in, K, H=512):\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, H),\n",
    "        nn.BatchNorm1d(H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, K))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss(beta, f_hat, y, w):\n",
    "    y_hat = np.exp(beta*f_hat)\n",
    "    den = (np.exp(beta*f_hat)).sum(axis=1)\n",
    "    y_hat = np.array([y_hat[i]/den[i] for i in range(len(den))])\n",
    "    loss = w*((y * (1- y_hat)).sum(axis=1))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor(1).float()\n",
    "f_hat = torch.tensor([[1, 2, 4], [1, 2, 3]]).float()\n",
    "y = torch.tensor([[0, 0, 1], [0, 0, 1]]).float()\n",
    "w = torch.tensor([1, 1]).float()\n",
    "#sofmax_loss(beta, f_hat, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2455)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_hat = beta*f_hat\n",
    "y_hat = F.softmax(f_hat, dim=1)\n",
    "loss = (y*(1-y_hat)).sum(dim=1)\n",
    "(w*loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounded_loss(beta, y_hat, y , w):\n",
    "    y_hat = beta*y_hat\n",
    "    y_hat = F.softmax(y_hat, dim=1)\n",
    "    loss = (y*(1-y_hat)).sum(dim=1)\n",
    "    return (w*loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, K, learning_rate = 0.01, epochs=100):\n",
    "    beta = 1\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    KK = epochs//10\n",
    "    for t in range(epochs):\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        for x, y, w in train_dl:\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda().long()\n",
    "            w = w.cuda().float()\n",
    "            y_onehot = torch.FloatTensor(y.shape[0], K).cuda()\n",
    "            y_onehot.zero_()\n",
    "            y_onehot = y_onehot.scatter_(1, y.unsqueeze(1), 1)\n",
    "            y_hat = model(x)\n",
    "            loss = bounded_loss(beta, y_hat, y_onehot , w)\n",
    "       \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()*y.size(0)\n",
    "            total += y.size(0)\n",
    "        if t % KK == 0: print(total_loss/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reasign_points(train_X, model):\n",
    "    x = torch.tensor(train_X).float()\n",
    "    y_hat = model(x.cuda())\n",
    "    _, pred = torch.max(y_hat, 1)\n",
    "    data = {'index': range(len(train_X)), 'group': pred.cpu().numpy()  }\n",
    "    return pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_groups(groups):\n",
    "    old2new = {x:i for i,x in enumerate(groups.group.unique())}\n",
    "    groups.group = np.array([old2new[x] for x in groups.group.values])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, y, oracle, models):\n",
    "    x = torch.tensor(X).float()\n",
    "    y = torch.tensor(y).float()\n",
    "    y_hat = oracle(x.cuda())\n",
    "    _, ass = torch.max(y_hat, 1)\n",
    "    preds = []\n",
    "    ys = []\n",
    "    for i in range(len(models)):\n",
    "        xx = x[ass==i]\n",
    "        yy = y[ass==i]\n",
    "        if len(xx) > 0:\n",
    "            pred = models[i].predict(xx.cpu().numpy())\n",
    "            preds.append(pred)\n",
    "            ys.append(yy.cpu().numpy())\n",
    "    preds = np.hstack(preds)\n",
    "    ys = np.hstack(ys)\n",
    "    r2 = r2_score(ys, preds)\n",
    "    res = (ys - preds)**2\n",
    "    return res.mean(), r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_assignments(train_X, K=6):\n",
    "    data = {'index': range(len(train_X)), 'group':  np.random.choice(K, len(train_X)) }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OracleDataset(Dataset):\n",
    "    def __init__(self, X, y, w):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.w[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difficult problems 5, 7, 22\n",
    "X, y = fetch_data(list_dataset[2], return_X_y=True, local_cache_dir='/data2/yinterian/pmlb/')\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=[1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 4, 8, 16, 32, 64]\n",
    "ridge_reg = RidgeCV(alphas=alphas)\n",
    "ridge_reg.fit(train_X, train_y)\n",
    "alpha = ridge_reg.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "print(alpha) \n",
    "K = 6\n",
    "groups = random_assignments(train_X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training points 750, number iterations 228\n",
      "K is  6\n",
      "models\n",
      "6\n",
      "(750, 6)\n",
      "extended\n",
      "0.4250280559062958\n",
      "0.4101625680923462\n",
      "0.40639010071754456\n",
      "0.40533706545829773\n",
      "0.4050077497959137\n",
      "0.4048629403114319\n",
      "0.4047868549823761\n",
      "0.40475910902023315\n",
      "0.404745489358902\n",
      "0.4047374427318573\n",
      "0.4047320783138275\n",
      "loss 2.4282719080885133 2.2115064093700876\n",
      "R^2 0.39795599979525886 0.38664404278362496\n",
      "best test_r2 0.38664404278362496\n",
      "K is  6\n",
      "models\n",
      "6\n",
      "(750, 6)\n",
      "extended\n",
      "0.6150661706924438\n",
      "0.4326910972595215\n",
      "0.42248833179473877\n",
      "0.41927003860473633\n",
      "0.4179413318634033\n",
      "0.4173830449581146\n",
      "0.41688966751098633\n",
      "0.4160519242286682\n",
      "0.41550707817077637\n",
      "0.41513335704803467\n",
      "0.4148763120174408\n",
      "loss 2.485776852486509 2.328313075371263\n",
      "R^2 0.3836987386369839 0.3542479963010777\n",
      "best test_r2 0.38664404278362496\n",
      "K is  4\n",
      "models\n",
      "4\n",
      "(750, 4)\n",
      "extended\n",
      "0.7650496363639832\n",
      "0.623860776424408\n",
      "0.6221958994865417\n",
      "0.6201805472373962\n",
      "0.6188361644744873\n",
      "0.6147842407226562\n",
      "0.612872838973999\n",
      "0.6120323538780212\n",
      "0.6114459037780762\n",
      "0.6113165616989136\n",
      "0.6112635731697083\n",
      "loss 2.4445282172923246 2.247518153516911\n",
      "R^2 0.3939255560096896 0.3766562725883318\n",
      "best test_r2 0.38664404278362496\n",
      "K is  3\n",
      "models\n",
      "3\n",
      "(750, 3)\n",
      "extended\n",
      "1.0170862674713135\n",
      "0.8294008374214172\n",
      "0.8242917060852051\n",
      "0.8235459327697754\n",
      "0.8232490420341492\n",
      "0.8231378197669983\n",
      "0.8230722546577454\n",
      "0.8230145573616028\n",
      "0.8229586482048035\n",
      "0.8229156136512756\n",
      "0.8228873610496521\n",
      "loss 2.4684337416693984 2.26101576884172\n",
      "R^2 0.3879986342860451 0.3729127416030227\n",
      "best test_r2 0.38664404278362496\n",
      "K is  2\n",
      "models\n",
      "2\n",
      "(750, 2)\n",
      "extended\n",
      "1.2861295938491821\n",
      "1.230057716369629\n",
      "1.2282662391662598\n",
      "1.2277238368988037\n",
      "1.2273985147476196\n",
      "1.227238655090332\n",
      "1.2271491289138794\n",
      "1.2270921468734741\n",
      "1.227051854133606\n",
      "1.2270212173461914\n",
      "1.2269964218139648\n",
      "loss 2.4536675988245276 2.2620818483042173\n",
      "R^2 0.39165961956380935 0.37261706704091513\n",
      "best test_r2 0.38664404278362496\n",
      "dataset 712_chscase_geyser1 K 6 ISL_r^2 0.3866 RF_r^2 0.3520 Ridge_r^2 0.3684 Lasso_r^2 0.3682\n"
     ]
    }
   ],
   "source": [
    "f = open('out.log', 'w+')\n",
    "batch_size = 100000\n",
    "# number of iterations depends on the number of training points\n",
    "N = train_X.shape[0]\n",
    "N_iter = int(10000/np.log(N)**2)\n",
    "print(\"Number of training points %d, number iterations %d\" % (N, N_iter))\n",
    "\n",
    "best_train_r2 = None\n",
    "best_K = None\n",
    "best_test_r2 = None\n",
    "for i in range(5):\n",
    "    print(\"K is \", K)\n",
    "    models = fit_K_models(train_X, train_y, groups, alpha, K)\n",
    "    print(\"models\")\n",
    "    X_ext, y_ext, w_ext = create_extended_dataset(train_X, train_y, models)\n",
    "    print(\"extended\")\n",
    "    train_ds = OracleDataset(X_ext, y_ext, w_ext)\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    model = create_model(train_X.shape[1], K, H=100).cuda()\n",
    "    train_model(model, train_dl, K, 0.01, N_iter)\n",
    "    groups = reasign_points(train_X, model)\n",
    "    if len(groups.group.unique()) < K:\n",
    "        K = len(groups.group.unique()) \n",
    "        groups = relabel_groups(groups)\n",
    "    train_loss, train_r2 = compute_loss(train_X, train_y, model, models)\n",
    "    if best_train_r2 == None:\n",
    "        best_train_r2 = train_r2\n",
    "        \n",
    "    test_loss, test_r2 = compute_loss(test_X, test_y, model, models)\n",
    "    if train_r2 >= best_train_r2:\n",
    "        best_train_r2 = train_r2\n",
    "        best_test_r2 = test_r2\n",
    "        best_K = K\n",
    "    print(\"loss\", train_loss, test_loss)\n",
    "    print(\"R^2\", train_r2, test_r2)\n",
    "    print(\"best test_r2\", best_test_r2)\n",
    "    if K == 1:\n",
    "        print(\"K\", K)\n",
    "        break\n",
    "\n",
    "r2_rf, r2_ridge, r2_lasso = other_scores(train_X, test_X, train_y, test_y)\n",
    "results = \"dataset %s K %d ISL_r^2 %.4f RF_r^2 %.4f Ridge_r^2 %.4f Lasso_r^2 %.4f\" %(dataset, best_K, best_test_r2, r2_rf, r2_ridge, r2_lasso)\n",
    "print(results)\n",
    "f.write(results)\n",
    "f.write('\\n')\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset, best_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_scores(train_X, test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750000, 18)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.26777153, -0.76656866,  0.43695488, -0.31608791,  0.26732423,\n",
       "       -0.75775435, -1.87686498, -0.1415347 ,  0.00854943,  1.24014095,\n",
       "        0.09577373,  1.22230522, -0.05583522,  0.69242445, -0.12679788,\n",
       "        1.92621476,  1.45341647, -1.25307813])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
