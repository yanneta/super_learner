{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNetCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1027_ESL', '1028_SWD', '1029_LEV', '1030_ERA', '1089_USCrime', '1096_FacultySalaries', '1191_BNG_pbc', '1193_BNG_lowbwt', '1196_BNG_pharynx', '1199_BNG_echoMonths', '1201_BNG_breastTumor', '1203_BNG_pwLinear', '1595_poker', '192_vineyard', '195_auto_price', '197_cpu_act', '201_pol', '207_autoPrice', '210_cloud', '215_2dplanes', '218_house_8L', '225_puma8NH', '227_cpu_small', '228_elusage', '229_pwLinear', '230_machine_cpu', '294_satellite_image', '344_mv', '4544_GeographicalOriginalofMusic', '485_analcatdata_vehicle', '503_wind', '505_tecator', '519_vinnie', '522_pm10', '523_analcatdata_neavote', '527_analcatdata_election2000', '529_pollen', '537_houses', '542_pollution', '547_no2', '556_analcatdata_apnea2', '557_analcatdata_apnea1', '560_bodyfat', '561_cpu', '562_cpu_small', '564_fried', '573_cpu_act', '574_house_16H', '579_fri_c0_250_5', '581_fri_c3_500_25', '582_fri_c1_500_25', '583_fri_c1_1000_50', '584_fri_c4_500_25', '586_fri_c3_1000_25', '588_fri_c4_1000_100', '589_fri_c2_1000_25', '590_fri_c0_1000_50', '591_fri_c1_100_10', '592_fri_c4_1000_25', '593_fri_c1_1000_10', '594_fri_c2_100_5', '595_fri_c0_1000_10', '596_fri_c2_250_5', '597_fri_c2_500_5', '598_fri_c0_1000_25', '599_fri_c2_1000_5', '601_fri_c1_250_5', '602_fri_c3_250_10', '603_fri_c0_250_50', '604_fri_c4_500_10', '605_fri_c2_250_25', '606_fri_c2_1000_10', '607_fri_c4_1000_50', '608_fri_c3_1000_10', '609_fri_c0_1000_5', '611_fri_c3_100_5', '612_fri_c1_1000_5', '613_fri_c3_250_5', '615_fri_c4_250_10', '616_fri_c4_500_50', '617_fri_c3_500_5', '618_fri_c3_1000_50', '620_fri_c1_1000_25', '621_fri_c0_100_10', '622_fri_c2_1000_50', '623_fri_c4_1000_10', '624_fri_c0_100_5', '626_fri_c2_500_50', '627_fri_c2_500_10', '628_fri_c3_1000_5', '631_fri_c1_500_5', '633_fri_c0_500_25', '634_fri_c2_100_10', '635_fri_c0_250_10', '637_fri_c1_500_50', '641_fri_c1_500_10', '643_fri_c2_500_25', '644_fri_c4_250_25', '645_fri_c3_500_50', '646_fri_c3_500_10', '647_fri_c1_250_10', '648_fri_c1_250_50', '649_fri_c0_500_5', '650_fri_c0_500_50', '651_fri_c0_100_25', '653_fri_c0_250_25', '654_fri_c0_500_10', '656_fri_c1_100_5', '657_fri_c2_250_10', '658_fri_c3_250_25', '659_sleuth_ex1714', '663_rabe_266', '665_sleuth_case2002', '666_rmftsa_ladata', '678_visualizing_environmental', '687_sleuth_ex1605', '690_visualizing_galaxy', '695_chatfield_4', '706_sleuth_case1202', '712_chscase_geyser1']\n"
     ]
    }
   ],
   "source": [
    "from pmlb import fetch_data, regression_dataset_names\n",
    "\n",
    "print(regression_dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028_SWD (1000, 10)\n",
      "1029_LEV (1000, 4)\n",
      "1030_ERA (1000, 4)\n",
      "1191_BNG_pbc (1000000, 18)\n",
      "1193_BNG_lowbwt (31104, 9)\n",
      "1196_BNG_pharynx (1000000, 10)\n",
      "1199_BNG_echoMonths (17496, 9)\n",
      "1201_BNG_breastTumor (116640, 9)\n",
      "1203_BNG_pwLinear (177147, 10)\n",
      "1595_poker (1025010, 10)\n",
      "197_cpu_act (8192, 21)\n",
      "201_pol (15000, 48)\n",
      "215_2dplanes (40768, 10)\n",
      "218_house_8L (22784, 8)\n",
      "225_puma8NH (8192, 8)\n",
      "227_cpu_small (8192, 12)\n",
      "294_satellite_image (6435, 36)\n",
      "344_mv (40768, 10)\n",
      "4544_GeographicalOriginalofMusic (1059, 117)\n",
      "503_wind (6574, 14)\n",
      "529_pollen (3848, 4)\n",
      "537_houses (20640, 8)\n",
      "562_cpu_small (8192, 12)\n",
      "564_fried (40768, 10)\n",
      "573_cpu_act (8192, 21)\n",
      "574_house_16H (22784, 16)\n",
      "583_fri_c1_1000_50 (1000, 50)\n",
      "586_fri_c3_1000_25 (1000, 25)\n",
      "588_fri_c4_1000_100 (1000, 100)\n",
      "589_fri_c2_1000_25 (1000, 25)\n",
      "590_fri_c0_1000_50 (1000, 50)\n",
      "592_fri_c4_1000_25 (1000, 25)\n",
      "593_fri_c1_1000_10 (1000, 10)\n",
      "595_fri_c0_1000_10 (1000, 10)\n",
      "598_fri_c0_1000_25 (1000, 25)\n",
      "599_fri_c2_1000_5 (1000, 5)\n",
      "606_fri_c2_1000_10 (1000, 10)\n",
      "607_fri_c4_1000_50 (1000, 50)\n",
      "608_fri_c3_1000_10 (1000, 10)\n",
      "609_fri_c0_1000_5 (1000, 5)\n",
      "612_fri_c1_1000_5 (1000, 5)\n",
      "618_fri_c3_1000_50 (1000, 50)\n",
      "620_fri_c1_1000_25 (1000, 25)\n",
      "622_fri_c2_1000_50 (1000, 50)\n",
      "623_fri_c4_1000_10 (1000, 10)\n",
      "628_fri_c3_1000_5 (1000, 5)\n"
     ]
    }
   ],
   "source": [
    "list_dataset = []\n",
    "\n",
    "for dataset in regression_dataset_names:\n",
    "    X, y = fetch_data(dataset, return_X_y=True, local_cache_dir='/data2/yinterian/pmlb/')\n",
    "    if X.shape[0] >= 1000:\n",
    "        print(dataset, X.shape)\n",
    "        list_dataset.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_data(list_dataset[3], return_X_y=True, local_cache_dir='/data2/yinterian/pmlb/')\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 5)]\n",
    "max_depth = [int(x) for x in np.linspace(3, 30, num = 5)]\n",
    "max_depth.append(None)\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 57, 105, 152, 200], 'max_depth': [3, 9, 16, 23, 30, None]}\n"
     ]
    }
   ],
   "source": [
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf = RandomForestRegressor()\n",
    "#rf_cv = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 20, cv = 3, verbose=2,\n",
    "#                           random_state=42, n_jobs = 2)\n",
    "#rf_cv.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=[1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 4, 8, 16, 32, 64, 132]\n",
    "def other_scores(train_X, test_X, train_y, test_y):\n",
    "    rf = RandomForestRegressor(n_estimators=10, max_depth=15, n_jobs=10)\n",
    "    ridge  = RidgeCV(cv=5, alphas=alphas)\n",
    "    lasso = ElasticNetCV(cv=5, random_state=0, l1_ratio=1)\n",
    "    dt = DecisionTreeRegressor(min_samples_leaf=10)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    test_X = scaler.transform(test_X)\n",
    "    \n",
    "    rf.fit(train_X, train_y)\n",
    "    lasso.fit(train_X, train_y)\n",
    "    ridge.fit(train_X, train_y)\n",
    "    dt.fit(train_X, train_y)\n",
    "    scores = [x.score(test_X, test_y) for x in [rf, ridge, lasso, dt]]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionally interpretable super learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  group\n",
       "0      0      5\n",
       "1      1      0\n",
       "2      2      3\n",
       "3      3      3\n",
       "4      4      2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_assignments(train_X, K=6):\n",
    "    data = {'index': range(len(train_X)), 'group':  np.random.choice(K, len(train_X)) }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "groups = random_assignments(train_X, K=6)\n",
    "groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=[1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 4, 8, 16, 32, 64, 132]\n",
    "class BaseModel:\n",
    "    def __init__(self, model_type):\n",
    "        self.model_type = model_type\n",
    "        self.model = self.create_model()\n",
    "        if model_type not in range(1,7):\n",
    "            print(\"model_type should be in the interval [1, 6]\")\n",
    "    \n",
    "    def create_model(self):\n",
    "        method_name = 'model_' + str(self.model_type)\n",
    "        method = getattr(self, method_name, lambda: \"nothing\")\n",
    "        return method()\n",
    "    \n",
    "    def model_1(self):\n",
    "        return RidgeCV(cv=5, alphas=alphas)\n",
    "    \n",
    "    def model_2(self):\n",
    "        return ElasticNetCV(cv=5, random_state=0, l1_ratio=0.5)\n",
    "\n",
    "    def model_3(self):\n",
    "        return ElasticNetCV(cv=5, random_state=0, l1_ratio=1)\n",
    "\n",
    "    def model_4(self):\n",
    "        return DecisionTreeRegressor(max_depth=1)\n",
    "    \n",
    "    def model_5(self):\n",
    "        return DecisionTreeRegressor(max_depth=3)\n",
    "    \n",
    "    def model_6(self):\n",
    "        return DecisionTreeRegressor(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.tree.tree.DecisionTreeRegressor"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = BaseModel(6)\n",
    "type(r.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=[1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 4, 8, 16, 32, 64, 132]\n",
    "def fit_K_models(train_X, train_y, groups, model_types, K=6):\n",
    "    models = []\n",
    "    for k in range(K):\n",
    "        ind = groups[groups[\"group\"] == k].index.values\n",
    "        X = train_X[ind]\n",
    "        y = train_y[ind]\n",
    "        if len(ind) > 10:\n",
    "            base_model = BaseModel(model_types[k])\n",
    "            base_model.model.fit(X, y)\n",
    "            models.append(base_model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_K_model_loss(train_X, train_y, models):\n",
    "    L = []\n",
    "    for i in range(len(models)):\n",
    "        loss = (models[i].model.predict(train_X) - train_y)**2\n",
    "        L.append(loss)\n",
    "    L = np.array(L)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(L, K):\n",
    "    JI_K = inv(np.ones((K, K)) - np.identity(K))\n",
    "    W = []\n",
    "    for i in range(L.shape[1]):\n",
    "        w_i = np.matmul(JI_K, L[:,i])\n",
    "        W.append(w_i)\n",
    "    return np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_dataset(train_X, train_y, models):\n",
    "    K = len(models)\n",
    "    N = train_X.shape[0]\n",
    "    L = compute_K_model_loss(train_X, train_y, models)\n",
    "    W = compute_weights(L, K)\n",
    "    X_ext = []\n",
    "    y_ext = []\n",
    "    w_ext = []\n",
    "    for i in range(K):\n",
    "        X_ext.append(train_X.copy())\n",
    "        y_ext.append(i*np.ones(N))\n",
    "        w_ext.append(W[:, i])\n",
    "    X_ext = np.concatenate(X_ext, axis=0)\n",
    "    y_ext = np.concatenate(y_ext, axis=0)\n",
    "    w_ext = np.concatenate(w_ext, axis=0)\n",
    "    return X_ext, y_ext, w_ext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(D_in, K, H=512):\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(D_in, H),\n",
    "        nn.BatchNorm1d(H),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(H, K))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss(beta, f_hat, y, w):\n",
    "    y_hat = np.exp(beta*f_hat)\n",
    "    den = (np.exp(beta*f_hat)).sum(axis=1)\n",
    "    y_hat = np.array([y_hat[i]/den[i] for i in range(len(den))])\n",
    "    loss = w*((y * (1- y_hat)).sum(axis=1))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor(1).float()\n",
    "f_hat = torch.tensor([[1, 2, 4], [1, 2, 3]]).float()\n",
    "y = torch.tensor([[0, 0, 1], [0, 0, 1]]).float()\n",
    "w = torch.tensor([1, 1]).float()\n",
    "#sofmax_loss(beta, f_hat, y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2455)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_hat = beta*f_hat\n",
    "y_hat = F.softmax(f_hat, dim=1)\n",
    "loss = (y*(1-y_hat)).sum(dim=1)\n",
    "(w*loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounded_loss(beta, y_hat, y , w):\n",
    "    y_hat = beta*y_hat\n",
    "    y_hat = F.softmax(y_hat, dim=1)\n",
    "    loss = (y*(1-y_hat)).sum(dim=1)\n",
    "    return (w*loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, K, learning_rate = 0.01, epochs=100):\n",
    "    beta = 1\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    KK = epochs//10\n",
    "    for t in range(epochs):\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        for x, y, w in train_dl:\n",
    "            x = x.cuda().float()\n",
    "            y = y.cuda().long()\n",
    "            w = w.cuda().float()\n",
    "            y_onehot = torch.FloatTensor(y.shape[0], K).cuda()\n",
    "            y_onehot.zero_()\n",
    "            y_onehot = y_onehot.scatter_(1, y.unsqueeze(1), 1)\n",
    "            y_hat = model(x)\n",
    "            loss = bounded_loss(beta, y_hat, y_onehot , w)\n",
    "       \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()*y.size(0)\n",
    "            total += y.size(0)\n",
    "        if t % KK == 0: print(total_loss/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reasign_points(train_X, model):\n",
    "    x = torch.tensor(train_X).float()\n",
    "    y_hat = model(x.cuda())\n",
    "    _, pred = torch.max(y_hat, 1)\n",
    "    data = {'index': range(len(train_X)), 'group': pred.cpu().numpy()  }\n",
    "    return pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_groups(groups, models):\n",
    "    unique_models = groups.group.unique()\n",
    "    old2new = {x:i for i,x in enumerate(unique_models)}\n",
    "    ratios = []\n",
    "    model_types = [models[i].model_type for i in unique_models]\n",
    "    groups.group = np.array([old2new[x] for x in groups.group.values])\n",
    "    return groups, model_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, y, oracle, models):\n",
    "    x = torch.tensor(X).float()\n",
    "    y = torch.tensor(y).float()\n",
    "    y_hat = oracle(x.cuda())\n",
    "    _, ass = torch.max(y_hat, 1)\n",
    "    preds = []\n",
    "    ys = []\n",
    "    for i in range(len(models)):\n",
    "        xx = x[ass==i]\n",
    "        yy = y[ass==i]\n",
    "        if len(xx) > 0:\n",
    "            pred = models[i].model.predict(xx.cpu().numpy())\n",
    "            preds.append(pred)\n",
    "            ys.append(yy.cpu().numpy())\n",
    "    preds = np.hstack(preds)\n",
    "    ys = np.hstack(ys)\n",
    "    r2 = r2_score(ys, preds)\n",
    "    res = (ys - preds)**2\n",
    "    return res.mean(), r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_loss(X, y, model):\n",
    "    pred = model.model.predict(X)\n",
    "    r2 = r2_score(y, pred)\n",
    "    res = (y - pred)**2\n",
    "    return res.mean(), r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_assignments(train_X, K=6):\n",
    "    data = {'index': range(len(train_X)), 'group':  np.random.choice(K, len(train_X)) }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OracleDataset(Dataset):\n",
    "    def __init__(self, X, y, w):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.w[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029_LEV\n"
     ]
    }
   ],
   "source": [
    "# difficult problems 5, 7, 22\n",
    "dataset = list_dataset[1]\n",
    "print(dataset)\n",
    "X, y = fetch_data(dataset, return_X_y=True, local_cache_dir='/data2/yinterian/pmlb/')\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y)\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "groups = random_assignments(train_X, K)\n",
    "\n",
    "batch_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training points 750, number iterations 228\n",
      "iter 0\n",
      "K is  6\n",
      "models\n",
      "extended\n",
      "0.08806014060974121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yinterian/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06872911751270294\n",
      "0.0670401081442833\n",
      "0.06642203778028488\n",
      "0.06605097651481628\n",
      "0.06574933975934982\n",
      "0.06559977680444717\n",
      "0.06550410389900208\n",
      "0.06543835252523422\n",
      "0.06538630276918411\n",
      "0.06534914672374725\n",
      "loss 0.39144440109478273 0.34945769247905784\n",
      "R^2 0.569525943295055 0.6169906943454344\n",
      "best test_r2 0.6169906943454344\n",
      "iter 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yinterian/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K is  3\n",
      "models\n",
      "extended\n",
      "0.17133112251758575\n",
      "0.1394306868314743\n",
      "0.1329386681318283\n",
      "0.1306695193052292\n",
      "0.12985892593860626\n",
      "0.1294344812631607\n",
      "0.12912632524967194\n",
      "0.12884938716888428\n",
      "0.1285523623228073\n",
      "0.12838436663150787\n",
      "0.12828843295574188\n",
      "loss 0.38413886145061715 0.36181266627290587\n",
      "R^2 0.577559894676777 0.6034495131495283\n",
      "best test_r2 0.6034495131495283\n",
      "iter 2\n",
      "K is  3\n",
      "models\n",
      "extended\n",
      "0.166066974401474\n",
      "0.13813632726669312\n",
      "0.13406679034233093\n",
      "0.131466343998909\n",
      "0.13088732957839966\n",
      "0.1305171102285385\n",
      "0.13021598756313324\n",
      "0.12998031079769135\n",
      "0.1298103630542755\n",
      "0.12929728627204895\n",
      "0.12903793156147003\n",
      "loss 0.3860956175894295 0.3748673487245655\n",
      "R^2 0.5754080367099725 0.5891414439069244\n",
      "best test_r2 0.6034495131495283\n",
      "iter 3\n",
      "K is  3\n",
      "models\n",
      "extended\n",
      "0.16999515891075134\n",
      "0.13558118045330048\n",
      "0.13117189705371857\n",
      "0.13009963929653168\n",
      "0.12944909930229187\n",
      "0.12872549891471863\n",
      "0.1282172054052353\n",
      "0.12778575718402863\n",
      "0.12737184762954712\n",
      "0.12723951041698456\n",
      "0.12716607749462128\n",
      "loss 0.38096610758640675 0.37593151553862847\n",
      "R^2 0.5810489935705998 0.5879751058885408\n",
      "best test_r2 0.5879751058885408\n",
      "iter 4\n",
      "K is  3\n",
      "models\n",
      "extended\n",
      "0.1639525592327118\n",
      "0.13644720613956451\n",
      "0.1335417479276657\n",
      "0.13223649561405182\n",
      "0.13128192722797394\n",
      "0.13076981902122498\n",
      "0.13031575083732605\n",
      "0.1301536113023758\n",
      "0.13007773458957672\n",
      "0.13002897799015045\n",
      "0.1299145668745041\n",
      "loss 0.3890586428831498 0.3759147605957785\n",
      "R^2 0.5721495777443062 0.5879934694820899\n",
      "best test_r2 0.5879751058885408\n",
      "iter 5\n",
      "K is  3\n",
      "models\n",
      "extended\n",
      "0.1633002609014511\n",
      "0.13738451898097992\n",
      "0.13497969508171082\n",
      "0.13151304423809052\n",
      "0.12990480661392212\n",
      "0.129098042845726\n",
      "0.12870165705680847\n",
      "0.12856903672218323\n",
      "0.1285114586353302\n",
      "0.12847822904586792\n",
      "0.12838706374168396\n",
      "loss 0.384677895489847 0.37713956815051275\n",
      "R^2 0.5769671152963073 0.5866510675227243\n",
      "best test_r2 0.5879751058885408\n",
      "iter 6\n",
      "K is  3\n",
      "models\n",
      "extended\n",
      "0.16666412353515625\n",
      "0.13751168549060822\n",
      "0.13615448772907257\n",
      "0.13576732575893402\n",
      "0.13550662994384766\n",
      "0.13535748422145844\n",
      "0.1352369785308838\n",
      "0.13333973288536072\n",
      "0.1317024827003479\n",
      "0.1314672827720642\n",
      "0.13137339055538177\n",
      "loss 0.39359123210790004 0.3671899764756003\n",
      "R^2 0.5671650587027811 0.5975559246226522\n",
      "best test_r2 0.5879751058885408\n",
      "iter 7\n",
      "K is  3\n",
      "models\n",
      "extended\n",
      "0.185191348195076\n",
      "0.13851478695869446\n",
      "0.13510434329509735\n",
      "0.13431361317634583\n",
      "0.13402646780014038\n",
      "0.1338549703359604\n",
      "0.13370762765407562\n",
      "0.13353224098682404\n",
      "0.1333327293395996\n",
      "0.13319754600524902\n",
      "0.13311485946178436\n",
      "loss 0.3987729632692194 0.3514516027024208\n",
      "R^2 0.5614666738810055 0.6148053477738074\n",
      "best test_r2 0.5879751058885408\n",
      "iter 8\n",
      "K is  2\n",
      "models\n",
      "extended\n",
      "0.2669442594051361\n",
      "0.2074054777622223\n",
      "0.20301757752895355\n",
      "0.20160949230194092\n",
      "0.2009388655424118\n",
      "0.20058174431324005\n",
      "0.2004072666168213\n",
      "0.20023615658283234\n",
      "0.19843359291553497\n",
      "0.19821764528751373\n",
      "0.1980082392692566\n",
      "loss 0.3949924180103064 0.363273720724882\n",
      "R^2 0.5656241650843779 0.6018481821065483\n",
      "best test_r2 0.5879751058885408\n",
      "iter 9\n",
      "K is  2\n",
      "models\n",
      "extended\n",
      "0.29540586471557617\n",
      "0.20457686483860016\n",
      "0.20140506327152252\n",
      "0.2008974850177765\n",
      "0.20068082213401794\n",
      "0.20052388310432434\n",
      "0.2003963142633438\n",
      "0.19987890124320984\n",
      "0.19963419437408447\n",
      "0.1995338499546051\n",
      "0.19947832822799683\n",
      "loss 0.3986304922790931 0.36146266118093023\n",
      "R^2 0.5616233501929182 0.6038331224107873\n",
      "best test_r2 0.5879751058885408\n",
      "iter 10\n",
      "K is  2\n",
      "models\n",
      "extended\n",
      "0.4201294779777527\n",
      "0.20734724402427673\n",
      "0.2071831077337265\n",
      "0.20717380940914154\n",
      "0.2071709781885147\n",
      "0.20716898143291473\n",
      "0.20716717839241028\n",
      "0.20716553926467896\n",
      "0.20716413855552673\n",
      "0.20716284215450287\n",
      "0.20716167986392975\n",
      "loss 0.4143000907039788 0.3540010155166545\n",
      "R^2 0.5443913867722314 0.6120111645212379\n",
      "best test_r2 0.5879751058885408\n",
      "iter 11\n",
      "K is  1\n",
      "dataset 1029_LEV K 3 ISL 0.5880 RF 0.5755 Ridge 0.6222 Lasso 0.6229 Cart 0.5509\n"
     ]
    }
   ],
   "source": [
    "f = open('out2.log', 'w+')\n",
    "batch_size = 100000\n",
    "# number of iterations depends on the number of training points\n",
    "N = train_X.shape[0]\n",
    "N_iter = int(10000/np.log(N)**2)\n",
    "print(\"Number of training points %d, number iterations %d\" % (N, N_iter))\n",
    "\n",
    "best_train_r2 = None\n",
    "best_K = None\n",
    "best_test_r2 = None\n",
    "model_types = range(1,7)\n",
    "for i in range(20):\n",
    "    print(\"iter\", i)\n",
    "    models = fit_K_models(train_X, train_y, groups, model_types, K)\n",
    "    K = len(models)\n",
    "    print(\"K is \", K)\n",
    "    if K == 1:\n",
    "        models[0].model.fit(train_X, train_y)\n",
    "        train_loss, train_r2 = compute_single_loss(train_X, train_y, models[0])\n",
    "        test_loss, test_r2 = compute_single_loss(test_X, test_y, models[0])\n",
    "        if train_r2 >= best_train_r2:\n",
    "            best_train_r2 = train_r2\n",
    "            best_test_r2 = test_r2\n",
    "            best_K = K\n",
    "        break\n",
    "    \n",
    "    print(\"models\")\n",
    "    X_ext, y_ext, w_ext = create_extended_dataset(train_X, train_y, models)\n",
    "    print(\"extended\")\n",
    "    train_ds = OracleDataset(X_ext, y_ext, w_ext)\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    model = create_model(train_X.shape[1], K, H=100).cuda()\n",
    "    train_model(model, train_dl, K, 0.01, N_iter)\n",
    "    groups = reasign_points(train_X, model)\n",
    "    if len(groups.group.unique()) < K:\n",
    "        K = len(groups.group.unique()) \n",
    "        groups, model_types = relabel_groups(groups, models)\n",
    "    train_loss, train_r2 = compute_loss(train_X, train_y, model, models)\n",
    "    if best_train_r2 == None:\n",
    "        best_train_r2 = train_r2\n",
    "        \n",
    "    test_loss, test_r2 = compute_loss(test_X, test_y, model, models)\n",
    "    if train_r2 >= best_train_r2:\n",
    "        best_train_r2 = train_r2\n",
    "        best_test_r2 = test_r2\n",
    "        best_K = K\n",
    "    print(\"loss\", train_loss, test_loss)\n",
    "    print(\"R^2\", train_r2, test_r2)\n",
    "    print(\"best test_r2\", best_test_r2)\n",
    "\n",
    "        \n",
    "scores = other_scores(train_X, test_X, train_y, test_y)\n",
    "model_str = [\"RF\", \"Ridge\", \"Lasso\", \"Cart\"]\n",
    "score_str = [\"%s %.4f\" % (s, score) for s,score in zip(model_str, scores)]\n",
    "score_str = \" \".join(score_str)\n",
    "results = \"dataset %s K %d ISL %.4f %s\"  %(dataset, best_K, best_test_r2, score_str)\n",
    "print(results)\n",
    "f.write(results)\n",
    "f.write('\\n')\n",
    "f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list_dataset[0], best_K, test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_scores(train_X, test_X, train_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
