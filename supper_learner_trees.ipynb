{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV, ElasticNetCV, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmlb import fetch_data, regression_dataset_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionally interpretable super learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_assignments(train_X, K=6):\n",
    "    data = {'index': range(len(train_X)), 'group':  np.random.choice(K, len(train_X)) }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "\n",
    "alphas=[1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 4, 8, 16, 32, 64, 132]\n",
    "class BaseModel:\n",
    "    def __init__(self, model_type):\n",
    "        self.model_type = model_type\n",
    "        self.model = self.create_model()\n",
    "        if model_type not in range(1,7):\n",
    "            print(\"model_type should be in the interval [1, 6]\")\n",
    "\n",
    "    def create_model(self):\n",
    "        method_name = 'model_' + str(self.model_type)\n",
    "        method = getattr(self, method_name, lambda: \"nothing\")\n",
    "        return method()\n",
    "\n",
    "    def model_1(self):\n",
    "        return RidgeCV(cv=5, alphas=alphas)\n",
    "\n",
    "    def model_2(self):\n",
    "        return ElasticNetCV(cv=5, random_state=0, l1_ratio=0.5)\n",
    "\n",
    "    def model_3(self):\n",
    "        return ElasticNetCV(cv=5, random_state=0, l1_ratio=1)\n",
    "\n",
    "    def model_4(self):\n",
    "        return DecisionTreeRegressor(max_depth=4, max_features=0.9)\n",
    "\n",
    "    def model_5(self):\n",
    "        return DecisionTreeRegressor(max_depth=5, max_features=0.9)\n",
    "\n",
    "    def model_6(self):\n",
    "        return DecisionTreeRegressor(max_depth=6, max_features=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(train_X, train_y, m_type):\n",
    "    N = train_X.shape[0]\n",
    "    n = int(2.5*N/np.log(N))\n",
    "    ind = np.random.choice(N, n, replace=False)\n",
    "    X = train_X[ind]\n",
    "    y = train_y[ind]\n",
    "    base_model = BaseModel(m_type)\n",
    "    base_model.model.fit(X, y)\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_initial_K_models(train_X, train_y, model_types):\n",
    "    models = []\n",
    "    N = train_X.shape[0]\n",
    "    n = int(3*N/np.log(N))\n",
    "    for k in range(len(model_types)):\n",
    "        ind = np.random.choice(N, n, replace=False)\n",
    "        X = train_X[ind]\n",
    "        y = train_y[ind]\n",
    "        if len(ind) > 10:\n",
    "            base_model = BaseModel(model_types[k])\n",
    "            base_model.model.fit(X, y)\n",
    "            models.append(base_model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=[1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 4, 8, 16, 32, 64, 132]\n",
    "\n",
    "def fit_K_models(train_X, train_y, oracle, models, K, p=0.8):\n",
    "    # sample to address overfitting \n",
    "    N = train_X.shape[0]\n",
    "    ind = np.random.choice(N, int(p*N), replace=False)\n",
    "    X = train_X[ind]\n",
    "    y = train_y[ind]\n",
    "    # assigning points using oracle\n",
    "    # this will be modified \n",
    "    groups = assign_points(X, oracle)\n",
    "                \n",
    "    if len(groups.group.unique()) < K:\n",
    "        groups, models = relabel_groups(groups, models)\n",
    "        K = len(groups.group.unique())\n",
    "        \n",
    "    model_types = [m.model_type for m in models]\n",
    "    models = []\n",
    "    for k in range(len(model_types)):\n",
    "        ind = groups[groups[\"group\"] == k].index.values\n",
    "        X_k = X[ind]\n",
    "        y_k = y[ind]\n",
    "        if len(ind) > 10:\n",
    "            base_model = BaseModel(model_types[k])\n",
    "            base_model.model.fit(X_k, y_k)\n",
    "            models.append(base_model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_K_model_loss(train_X, train_y, models):\n",
    "    L = []\n",
    "    for i in range(len(models)):\n",
    "        loss = (models[i].model.predict(train_X) - train_y)**2\n",
    "        L.append(loss)\n",
    "    L = np.array(L)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(L, K):\n",
    "    JI_K = inv(np.ones((K, K)) - np.identity(K))\n",
    "    W = []\n",
    "    for i in range(L.shape[1]):\n",
    "        w_i = np.matmul(JI_K, L[:,i])\n",
    "        W.append(w_i)\n",
    "    return np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_extended_dataset(train_X, train_y, models, p=0.7):\n",
    "    # sample to address overfitting\n",
    "    K = len(models)\n",
    "    N = train_X.shape[0]\n",
    "    n = int(p*N)\n",
    "    idx = np.random.choice(N, n, replace=False)\n",
    "    X = train_X[idx]\n",
    "    Y = train_y[idx]\n",
    "    L = compute_K_model_loss(X, Y, models)\n",
    "    W = compute_weights(L, K)\n",
    "    X_ext = []\n",
    "    y_ext = []\n",
    "    w_ext = []\n",
    "    for i in range(K):\n",
    "        X_ext.append(X.copy())\n",
    "        y_ext.append(i*np.ones(n))\n",
    "        w_ext.append(W[:, i])\n",
    "    X_ext = np.concatenate(X_ext, axis=0)\n",
    "    y_ext = np.concatenate(y_ext, axis=0)\n",
    "    w_ext = np.concatenate(w_ext, axis=0)\n",
    "    return X_ext, y_ext, w_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss(beta, f_hat, y, w):\n",
    "    y_hat = np.exp(beta*f_hat)\n",
    "    den = (np.exp(beta*f_hat)).sum(axis=1)\n",
    "    y_hat = np.array([y_hat[i]/den[i] for i in range(len(den))])\n",
    "    loss = w*((y * (1- y_hat)).sum(axis=1))\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounded_loss(beta, y_hat, y , w):\n",
    "    #y_hat = beta*y_hat\n",
    "    y_hat = F.softmax(y_hat, dim=1)\n",
    "    loss = (y*(1-y_hat)).sum(dim=1)\n",
    "    return (w*loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_points(X, model):\n",
    "    y_hat = model.predict(X).astype(int)\n",
    "    data = {'index': range(len(X)), 'group': y_hat}\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_groups(groups, models):\n",
    "    unique_models = groups.group.unique()\n",
    "    old2new = {x:i for i,x in enumerate(unique_models)}\n",
    "    model_subset = [models[i] for i in unique_models]\n",
    "    groups.group = np.array([old2new[x] for x in groups.group.values])\n",
    "    return groups, model_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tree_oracle_model(X, y, w, max_depth):\n",
    "    dtc = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    dtc.fit(X, y, sample_weight=w)\n",
    "    return dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lr_oracle_model(X, y, w):\n",
    "    lrc = LogisticRegressionCV(cv=5, random_state=0, multi_class='multinomial', n_jobs=5)\n",
    "    lrc.fit(X, y, sample_weight=w)\n",
    "    return lrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X, y, oracle, models):\n",
    "    y_hat = oracle.predict(X)\n",
    "    preds = []\n",
    "    ys = []\n",
    "    for i in range(len(models)):\n",
    "        xx = X[y_hat==i]\n",
    "        yy = y[y_hat==i]\n",
    "        if len(xx) > 0:\n",
    "            pred = models[i].model.predict(xx)\n",
    "            preds.append(pred)\n",
    "            ys.append(yy)\n",
    "    preds = np.hstack(preds)\n",
    "    ys = np.hstack(ys)\n",
    "    r2 = r2_score(ys, preds)\n",
    "    res = (ys - preds)**2\n",
    "    return res.mean(), r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_loss(X, y, model):\n",
    "    pred = model.model.predict(X)\n",
    "    r2 = r2_score(y, pred)\n",
    "    res = (y - pred)**2\n",
    "    return res.mean(), r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_models(train_X, train_y, valid_X, valid_y):\n",
    "    best_model = None\n",
    "    best_valid_r2 = 0\n",
    "    best_model_type = 0\n",
    "    for k in range(1,7):\n",
    "        base_model = BaseModel(k)\n",
    "        base_model.model.fit(train_X, train_y)\n",
    "        valid_r2 = base_model.model.score(valid_X, valid_y)\n",
    "        if valid_r2 > best_valid_r2:\n",
    "            best_valid_r2 = valid_r2\n",
    "            best_model_type = k\n",
    "            best_model = base_model.model\n",
    "    return best_valid_r2, best_model, [best_model_type]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datatest_split(dataset, state):\n",
    "    X, y = fetch_data(dataset, return_X_y=True, local_cache_dir='/data2/yinterian/pmlb/')\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=state, test_size = 0.2)\n",
    "    valid_X, test_X, valid_y, test_y = train_test_split(test_X, test_y, random_state=state, test_size =0.5)\n",
    "    scaler = StandardScaler()\n",
    "    train_X = scaler.fit_transform(train_X)\n",
    "    test_X = scaler.transform(test_X)\n",
    "    valid_X = scaler.transform(valid_X)\n",
    "    return train_X, valid_X, test_X, train_y, valid_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_loop(state, selected_datasets):\n",
    "    for dataset in selected_datasets:\n",
    "        train_X, valid_X, test_X, train_y, valid_y, test_y = get_datatest_split(dataset, state)\n",
    "\n",
    "        best_valid_r2, best_model, best_model_types = baseline_models(train_X, train_y, valid_X, valid_y)\n",
    "        best_test_r2 = best_model.score(test_X, test_y)\n",
    "        print(\"best valid R^2 %.3f best model type %d\" % (best_valid_r2, best_model_types[0]))\n",
    "        best_oracle = None\n",
    "        best_models = [best_model] \n",
    "\n",
    "        N = train_X.shape[0]\n",
    "        print(\"Number of training points %d\" % (N))\n",
    "\n",
    "        INIT_FLAG = True\n",
    "        oracle = None\n",
    "        for i in range(16):\n",
    "            if i == 8: INIT_FLAG = True\n",
    "            \n",
    "            if not INIT_FLAG:\n",
    "                models = fit_K_models(train_X, train_y, oracle, models, K, p=0.9)\n",
    "                if len(models) == 1:\n",
    "                    INIT_FLAG = True  \n",
    "            \n",
    "            if INIT_FLAG:\n",
    "                model_types = [x for x in range(1,7)] + [1,3,6,6,6,6,6,6]\n",
    "                models = fit_initial_K_models(train_X, train_y, model_types)\n",
    "                INIT_FLAG = False\n",
    "            \n",
    "            K = len(models)\n",
    "            print(\"Iteration %d K is %d\" % (i+1, K))\n",
    "            if K == 1:\n",
    "                INIT_FLAG = True\n",
    "\n",
    "            if not INIT_FLAG:\n",
    "                X_ext, y_ext, w_ext = create_extended_dataset(train_X, train_y, models, p=0.9)\n",
    "                #oracle = fit_tree_oracle_model(X_ext, y_ext, w_ext, max_depth=6)\n",
    "                oracle = fit_lr_oracle_model(X_ext, y_ext, w_ext)\n",
    "            \n",
    "            \n",
    "            if not INIT_FLAG:\n",
    "                train_loss, train_r2 = compute_loss(train_X, train_y, oracle, models)\n",
    "                valid_loss, valid_r2 = compute_loss(valid_X, valid_y, oracle, models)\n",
    "                test_loss, test_r2 = compute_loss(test_X, test_y, oracle, models)\n",
    "\n",
    "\n",
    "            print(\"train loss %.3f valid loss %.3f\", train_loss, valid_loss)\n",
    "            print(\"train R^2 %.3f valid R^2 %.3f\", train_r2, valid_r2)\n",
    "            if valid_r2 >= best_valid_r2:\n",
    "                best_train_r2 = train_r2\n",
    "                best_valid_r2 = valid_r2\n",
    "                best_K = K\n",
    "                best_models = models\n",
    "                best_model_types = [m.model_type for m in models]\n",
    "                best_test_r2 = test_r2 \n",
    "        \n",
    "        results = \"dataset %s state %d K %d test ISL %.3f valid ISL %.3f model_types %s\" % (\n",
    "                dataset, state, len(best_models), best_test_r2, best_valid_r2, str(best_model_types))\n",
    "        print(results)\n",
    "        #f.write(results)\n",
    "        #f.write('\\n')\n",
    "        #f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best valid R^2 0.796 best model type 6\n",
      "Number of training points 5148\n",
      "Iteration 1 K is 14\n",
      "train loss %.3f valid loss %.3f 0.8429688950933112 1.176194202335173\n",
      "train R^2 %.3f valid R^2 %.3f 0.828646644791988 0.7492767397576607\n",
      "Iteration 2 K is 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-48d588252bca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"294_satellite_image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-68-ba35166a5512>\u001b[0m in \u001b[0;36mmain_loop\u001b[0;34m(state, selected_datasets)\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mX_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_extended_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;31m#oracle = fit_tree_oracle_model(X_ext, y_ext, w_ext, max_depth=6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0moracle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_lr_oracle_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-179a370637c0>\u001b[0m in \u001b[0;36mfit_lr_oracle_model\u001b[0;34m(X, y, w)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_lr_oracle_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m                       )\n\u001b[0;32m-> 1790\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m             for train, test in folds)\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main_loop(1, [\"294_satellite_image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
